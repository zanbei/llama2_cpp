{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " revolutionize the way we live and work. It will transform industries, create new opportunities for businesses, and improve our daily lives in countless ways. However, it also poses significant challenges that need to be addressed.\n",
      "\n",
      "One of the biggest challenges facing AI is ensuring its safety and security. As AI becomes more prevalent, there will be an increased risk of cyberattacks and data breaches. This means that companies must invest in robust security measures to protect their customers' data and prevent unauthorized access to their systems.\n",
      "\n",
      "Another challenge facing AI is its potential to reinforce biases and perpetuate inequality. As algorithms are designed by human programmers, they may be prone to replicating and amplifying existing prejudices or biases within our society. Therefore, it is important to ensure that AI systems are developed with ethical considerations in mind, and that they do not perpetuate discrimination or exclusion.\n",
      "\n",
      "Finally, there is a need for transparency and accountability in the use of AI. As AI becomes more prevalent, it will be increasingly difficult to understand how decisions are being made by algorithms.\n"
     ]
    }
   ],
   "source": [
    "# from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "# # Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "# llm = AutoModelForCausalLM.from_pretrained(\"/home/ubuntu/llama2_cpp/firefly-llama2-13b-v1.2.Q2_K.gguf\", model_type=\"llama\", gpu_layers=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.session import Session\n",
    "\n",
    "#ECR URI\n",
    "image_uri = '969422986683.dkr.ecr.cn-northwest-1.amazonaws.com.cn/llama213bint4'\n",
    "role = 'arn:aws-cn:iam::969422986683:role/AmazonSageMaker-ExecutionRole-20200517T121567'\n",
    "# This can be dummy model file\n",
    "model_dir = 's3://sagemaker-cn-northwest-1-969422986683/model.tar.gz'\n",
    "\n",
    "# Create the SageMaker model instance\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    model_data=model_dir\n",
    ")\n",
    "\n",
    "model.deploy(\n",
    "    instance_type='ml.g4dn.2xlarge',\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name = 'llama2-cpp-test',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import json\n",
    "\n",
    "endpoint_name = 'llama2-cpp-test'\n",
    "data = {\"prompt\": \"how to learn english?\"}\n",
    "runtime_sagemaker_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "\n",
    "body = json.dumps(data)\n",
    "\n",
    "start = time.time()\n",
    "response = runtime_sagemaker_client.invoke_endpoint(\n",
    "    EndpointName = endpoint_name,\n",
    "    ContentType  = \"application/json\",\n",
    "    Body= body)\n",
    "\n",
    "cost = time.time() - start     \n",
    "result = response['Body'].read().decode('utf-8')\n",
    "\n",
    "print('Response: ', result)\n",
    "print(\"Cost Time:  %s seconds\" % (cost))\n",
    "print('Output Chars :', len(result))\n",
    "print('Speed: {:.2f} Chars/s'.format(len(result)/float(cost)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
